\documentclass[11pt,a4paper]{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{multicol}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{apacite}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage[noend]{algpseudocode}
\usepackage[nothing]{algorithm}
\usepackage{array}
\usepackage{xcolor}
\newcolumntype{T}{>{\tiny}l} % define a new column type for \tiny
\newcolumntype{H}{>{\Huge}l} % define a new column type for \Huge
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}

\usepackage{stackengine}
\newsavebox\mybox
\newcommand\Includegraphics[2][]{\sbox{\mybox}{%
\includegraphics[#1]{#2}}\abovebaseline[-.5\ht\mybox]{%
\addstackgap{\usebox{\mybox}}}}

\algnewcommand\And{\textbf{and} }
\algnewcommand\Or{\textbf{or} }

\def\SPSB#1#2{\rlap{\textsuperscript{{#1}}}\SB{#2}}
\def\SP#1{\textsuperscript{{#1}}}
\def\SB#1{\textsubscript{{#1}}}


\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand*{\field}[1]{\mathbb{#1}}%

\begin{document}  

\begin{titlepage} % Suppresses headers and footers on the title page

	\centering % Centre everything on the title page
	
	\scshape % Use small caps for all text on the title page
	
	\vspace*{\baselineskip} % White space at the top of the page
	
	%------------------------------------------------
	%	Title
	%------------------------------------------------
	
	
	\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt} % Thick horizontal rule
	\rule{\textwidth}{0.4pt} % Thin horizontal rule
	
	\vspace{0.75\baselineskip} % Whitespace above the title
	
	{\LARGE Implementation and Analysis of Acceleration Data Structures in Ray tracing\\} % Title
	
	\vspace{0.75\baselineskip} % Whitespace below the title
	
	\rule{\textwidth}{0.4pt}\vspace*{-\baselineskip}\vspace{3.2pt} % Thin horizontal rule
	\rule{\textwidth}{1.6pt} % Thick horizontal rule
	
	\vspace{2\baselineskip} % Whitespace after the title block
	
	%------------------------------------------------
	%	Subtitle
	%------------------------------------------------
	
	Master Project Rendering Track \\ 
	SS 2022 % Subtitle or further description
	
	\vspace*{3\baselineskip} % Whitespace under the subtitle
	
	%------------------------------------------------
	%	Editor(s)
	%------------------------------------------------
	
	Author
	
	\vspace{0.5\baselineskip} % Whitespace before the editors
	
	{\scshape\Large Alhajras Algdairy \\} % Editor list
	
			\vspace{0.5\baselineskip} % Whitespace before the editors

		Advisor
	
	\vspace{0.5\baselineskip} % Whitespace before the editors
	
	{\scshape\Large Prof. Dr.-Ing. Matthias Teschner\\} % Editor list

	\vspace{0.5\baselineskip} % Whitespace before the editors
		
	\textit{Albert-Ludwigs-University of Freiburg \\ Chair of Computer Graphics} % Editor affiliation
	
		
\begin{figure}[h]	
     \centering
         \includegraphics[width=3cm]{images/freiburg.png}
\end{figure}
	\vfill % Whitespace between editor names and publisher logo
	
	%------------------------------------------------
	%	Publisher
	%------------------------------------------------
	


	
	\vspace{0.3\baselineskip} % Whitespace under the publisher logo
	
	\today% Publication year
	

\end{titlepage}

\clearpage

\section*{Acknowledgments}
This project results from hard work and cumulative knowledge gained through seminars, labs, and lectures in the chair of computer graphics at the University of Freiburg under \textbf{Prof. Dr.-Ing. Matthias Teschner} guidness and supervision. Those materials and their resources were the fundamental building blocks to reaching this point with the proper feedback from the professor. The resources used in this project are been referenced and acknowledged wherever necessary.
\\
\section*{Abstract}
Improving the rendering time in a ray tracer is a challenging task. One of the improvement levels is to implement an acceleration data structure. There are two classifications of data structures namely, \textbf{spatial subdivision} and \textbf{object subdivision}. Both classifications will be covered in the report. For object subdivision, \textbf{Bounding Volume Hierarchies (BVH)} and \textbf{Linear Bounding Volume Hierarchies (LBVH)} will be implemented. For spatial subdivision, Kd-Tree is chosen. In this report, we will explore each method's strengths and weaknesses by using different scenes and models.
  
\noindent
\\
\textbf{Keywords:} [BVH] [LBVH] [KD-Tree] [ray tracing] [acceleration structure]  [object subdivision] [spatial
subdivision] 
\clearpage
\tableofcontents
\clearpage



\section{Introduction to Ray tracing}
\subsection{Overview}
Ray tracing is an algorithm to simulate how light behaves in a 3D scene to generate real-life digital images in a computer. This process is called rendering. Rendering is used in various applications, such as Gaming, Animation, and Engineering.

\noindent
\\
Ray tracers have three different implementations namely, Forward Ray tracing, Backward Ray tracing, and Hybrid Ray tracing; regardless of which implementation is used, the general idea of the algorithm is quite simple but extremely powerful; it is to project the 3D scene into a 2D plane (Image), to do so, a resolution must be chosen beforehand to divide the plane into small squares knows as (Pixels), next, we try to evaluate the color and illumination of each pixel. We cast several rays from the sensor (camera) toward the scene for each pixel. We search for any intersection by testing all the primitives, and if we hit one, we save it in a hit list. Depending on the distance between the sensor and the hit primitive, we can evaluate the nearest one to the sensor and pick its color. Shading is the next step, this includes knowing if the primitive is in a dark or bright region in the scene. This expensive process is recursively executed until we hit the light source or reach a predefined depth. For thousands of primitives and more, testing the intersection is a performance challenge as the process is linear in time.

\begin{figure}[h]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=8cm]{images/raytracer_2.jpg}
     \caption{A visual representation of ray tracing in which the rays are moving from the camera towards the scene. \protect\cite{Kimathi2020}}
     \label{fig:raytracer}
\end{figure}

\noindent
\\
Although the Rasterization method can be used to overcome these obstacles; Ray tracing algorithms can relatively provide more photo-realistic images than rasterization even though ray tracer consumes more time to render a scene. This is the reason why rasterization is used for real-time applications such as gaming more than raytracing; on the other hand, raytracing is more often used in offline applications such as simulations and interior design software.
\clearpage

\begin{figure}[h]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=10cm]{images/marbel_brush.png}
     \caption{NVIDIA RTX 3080 demo to realize real-time cinematic rendering.
\protect\cite{Burke2018}}
     \label{fig:rtxdemo}
\end{figure}

\noindent
\\
At Game Developers Conference, NVIDIA announced NVIDIA RTX™, a ray tracing technology that brings real-time gaming. The lighting, shadows, and surface reflection are so detailed in the marble scene that they look like a picture taken from a camera and not generated from a computer. The real challenge in real-time rendering is how to approximately render 60 high-quality frames per second.


\subsection{Motivation of using acceleration data structures}
In the ray tracing pipeline, we mentioned that each ray must execute an intersection test against all primitive contained in the scene. With $N$ number of pixels and $P$ number of primitives, this will produce a complexity of $\mathcal{O}(N.P)$. This is equivalent to a two-for-loop complexity $\mathcal{O}(n^2)$. Meaning for each pixel even if it does not intersect with any primitive we will have to perform an intersection test for all the primitives in the scene. The worst-case scenario is when the rays do not intersect with any primitive or model but the ray tracer has to trace the rays in different directions still, resulting in an empty image. 

\noindent
\\
Brute forcing complexity is high, it increases linearly with the increase of the number of primitives. Moreover, some features such as anti-aliasing require more rays per pixel which increases the complexity to  $\mathcal{O}(N.P.S)$ where $S$ is the number of samples per pixel. 

\noindent
\\
Generally using more samples will often produce a higher quality frame; additionally, for better illumination results, more recursion (Shadow rays) must be cast after each intersection. Hence, more rays are required for better quality but with fewer intersection tests as possible for better performance.

\noindent
\\
Giving a ray tracer that uses $S = 5$, $P = 100, 000$, and $N =  1, 280 $ x $1, 024$, $depth = 3$. This will give us a number of intersection tests, approximately $= 1, 280 * 1, 024 * 100, 000 * 5 * 3 = 1.96608*10^{12} $ intersection test. Assuming the machine used spends 0.01ms on each ray. This will result in 220 days of rendering one frame. Computers nowadays can handle this easily however the main challenge is scalability, some scenes contain millions of primitives making, rendering them by brute-forcing imposable.

\noindent
\\ 
Preprocessing algorithms to reorder and group the primitives to make them quickly traversed and tested can be used to overcome this challenge. \textbf{Spatial subdivision} and \textbf{object subdivision} are the two basic types of data acceleration structures. Spatial subdivision algorithms partition three-dimensional space into areas and keep track of which primitives overlap which regions. On the other hand, object subdivision algorithms gradually subdivide the scene's objects into smaller groups. This way, we can only test the primitives that have a higher probability to intersect with the ray rather than testing all primitives that are not relevant to the region the ray passes through. 

\clearpage

\section{Bounding Volume Hierarchies (BVH)}
\subsection{Concept}
The basic idea of the BVH is simple yet powerful. It is to wrap all primitives in a virtual bounding box. This box will act as metadata to show the limits of the primitive and has no idea of how the shape of the primitive inside it. This concept will make it easier to test the primitives because one can wrap a complex model with one bounding box, and if the ray intersects the bounding box of the model, then and only then can we test its primitives.


\begin{figure}[h]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=10cm]{images/bvs.png}
     \caption{Bounding volumes: sphere, axis-aligned bounding box (AABB), oriented bounding box (OBB), eight-direction discrete orientation polytope (8-DOP), convex hull . \protect\cite{Ericson2004}}
     \label{fig:boundingboxes}
\end{figure}


\noindent
\\
The bounding volume can have different shapes, as shown in Figure ~\ref{fig:boundingboxes}. Although simple bounding volumes provide faster intersection tests, they often suffer from fitting to the model, eventually, they produce a large region of space. A compact bounding volume, on the other hand, generates fewer overlaps with other bounding volumes in the scene, producing fewer intersection tests. For example, spheres are probably the easiest bounding volume to generate for each primitive, also its intersection test is trivial and not expensive, however, we can note from the previous figure that it produces more empty regions that will be tested but will miss the model eventually producing redundant tests. Using complex bounding volumes like \textbf{8-DOP} will have a higher probability of hitting the model and not missing it, but they are more difficult to generate and also more difficult to be tested. In this report, we will be using \textbf{AABB}, because it is easy to implement, easy to test its intersection, and has less memory consumption because it only needs to save two 3D variables the minimum and the maximum edges of the bounding box. One can use a combination of all of them but in this report, we will only use the AABB. 


\begin{figure}[h]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=8cm]{images/bvh_tree.png}
     \caption{BVH tree result by using AABB on a simple scene
. \protect\cite{Ericson2004} }
        \label{fig:boundingvolume}
\end{figure}

\noindent
\\
Figure ~\ref{fig:boundingboxes} shows a scene consists of six objects. Looking at the generated binary tree, we can note that every two objects are bounded by one AABB, then each two AABB are joined and bounded by a bigger AABB. We recursively do this until we reach the root node that covers the limits of the whole scene.This will create a hierarchy of AABBs and this is where the \textbf{Bounding Volume Hierarchies} name came from.

\noindent
\\
Without the BVH tree, we will have to go through all six objects for each ray intersection test, even for the rays that do not intersect with any object. On the other hand, when we introduced BVH, we can note that for the rays that do not even intersect with the root AABB node, we do not go further to test its children. This means we will only test once rather than six times. Looking at the sphere in Figure ~\ref{fig:boundingboxes}, if a ray intersects with it, we will only have to go through a path that goes $A \rightarrow B \rightarrow D \rightarrow Sphere$. These are four tests instead of six and these four tests are the worst-case scenario as the longest path in the tree equals three. 

\noindent
\\
The worse case complexity for a binary tree is $\mathcal{O}(n)$, but if it is a balanced tree, it becomes $\mathcal{O}(\log{}n)$, this is significant, but the catch is we should try to build a balanced binary tree. This is where splitting criteria come in handy. 



\subsection{Implemntation}
BVH is made of two phases, Construction of the tree, and Traversal over the tree.  

\subsubsection{Construction}
There are three methods to build the BVH binary tree: \textbf{Top-down}, \textbf{Bottom-up}, and \textbf{Insertion}. Top-down is arguably the most popular technique in practice, hence this method will be implemented in this report. It uses the \textbf{fit \& split} algorithm, where it starts with the whole model and encapsulates it with a BV and fits it, then tries to split it
into n children, usually two. It keeps recursively splitting and fitting until it reaches the leaves and assigns the primitives to them.

\noindent
\\
Building a BVH tree needs predefined parameters. The depth of the tree, maximum allowed number of primitives in the leaf nodes, splitting axis, and bounding volume for wrapping primitives. The depth of the tree will not be predefined for the BVH tree, this means the tree can go deeper as possible. The maximum allowed primitives for each leaf will be chosen to be one. For bounding volume as previously discussed, we will use only AABB. The splitting criteria and splitting axis will be discussed next.  
BVH tree can be constructed based on three different splitting criteria. There are four popular strategies to split the tree node:

\begin{itemize}
\item \textbf{Median of the centroid coordinates (Object median)}: The median of primitives, meaning if we have the next primitive positions in the x-axis as follows $\{1, 3, 3, 6, 7, 8, 9\}$ the median will be the primitive in the middle, which is $6$. This strategy will produce a well-balanced tree because it splits the primitives into two equal subtrees. Because this method is intuitive to implement and produces a well-balanced tree, this strategy will be adopted for the BVH tree. 

\item \textbf{Centroid method:}
This criteria focus on the bounding volume and not its primitives where it splits the AABB box into two half as follows:
\begin{equation}
\boldsymbol{c} = \frac{\boldsymbol{primitive_{AABB_{min}}}+\boldsymbol{primitive_{AABB_{max}}}}{2}
\end{equation}

\item  \textbf{Mean of centroid coordinates (Object mean)}: Using the mean of the primitives going back to the example $\{1, 3, 3, 6, 7, 8, 9\}$, the mean of this set is $5.2$, where the left child node will contain $\{1,3,3\}$ and the right child $\{6,7,8,9\}$

\item  \textbf{Spatial median}: Splitting the primitive's volume into two equal parts. For example, if we have four spheres with the next radius $\{1,1,1,4\}$, this strategy will split it as follow, the left child is $\{1,1,1\}$ and the right child is $\{4\}$ because it will split based on the volume/area of the sphere and not the position as the previous strategies. 


\end{itemize}


\begin{figure}[H]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=10cm]{images/bvh_split.png}
     \caption{An example of (a) Object median splitting (b) Object mean splitting (c) Spatial median
splitting based on \protect\cite{Ericson2004}}
        \label{fig:dice}
\end{figure}

\noindent
\\
For choosing the splitting axis, one can use any axis, but this is a naive way to split. What happens if all primitives have the same z-axis and y-axis, but only the x-axis is changing, and we randomly choose to split by z-axis? This will usually produce an unbalanced tree. The optimal way is to calculate the longest axis for each node (AABB box). This way, we can try to split by the longest axis, which will produce a better-balanced tree. We can find the longest axis of the AABB box by using its diagonal $d$. 


\begin{equation}
\textbf{d} = \textbf{AABB}_{max} - \textbf{AABB}_{min}
\end{equation}

\noindent
\\
In Figure ~\ref{fig:aabbexample}, we have four spheres wrapped up by AABB. If we would like to choose one axis to split from, we can randomly start with the x-axis. As it is illustrated, choosing this axis will not give us a middle point to split point since all spheres have the same x-axis. Same for the y-axis. On the other hand, we can see that the Z-axis will split the AABB box into two AABB boxes, each containing two spheres. Again we can rechoose the z-axis to split those two AABB boxes. Finding the longest diagonal will indicate the largest spreading direction of the primitives in the scene. After finding $d$ we find the maximum axis of the diagonal as the next splitting axis.

\begin{figure}[H]	
     \centering
     \begin{subfigure}[t]{0.3\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/longaxis.png}
         \caption{}
         \label{fig:pi_4000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.3\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/LONGAXIS_Y.png}
         \caption{}
         \label{fig:pi_5000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.3\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/LONGAXIS_Z.png}
         \caption{}
         \label{fig:pi_18000}
     \end{subfigure}
        \captionsetup{justification=centering,margin=2cm}
        \caption{(a) Finding the diagonal of the AABB box is shown in green. (b) Vertical view of the scene where choosing either x-axis or y-axis will not make difference. (c) Horizontal view of the scene where the z-axis makes the perfect splitting axis due to its wide distribution.}
        \label{fig:aabbexample}
\end{figure}

\subsubsection{Visual Illustration}
For a better illustration of how to build the BVH tree by using the centroid coordinates splitting criteria and also by choosing the longest axis to split from, we will look at the next scene as an example: 

\begin{figure}[h]	
     \centering
     \begin{subfigure}[t]{0.3\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/example_bvh/2_g.png}
         \captionsetup{justification=centering,margin=0.1cm}
         \caption{Root node and its AABB (Black) that covers all primitives and it's diagonal (Gray).}
         \label{fig:pi_4000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.3\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/example_bvh/3_g.png}
         \captionsetup{justification=centering,margin=0.1cm}
         \caption{The second level in the tree splits the primitives into two groups by creating two internal nodes.}
         \label{fig:pi_5000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[t]{0.3\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/example_bvh/4_g.png}
         \captionsetup{justification=centering,margin=0.1cm}
         \caption{The third level in the tree splits the primitives into four groups, creating three internal nodes and a leaf node.}
         \label{fig:pi_18000}
     \end{subfigure}
        \captionsetup{justification=centering,margin=2cm}
        \caption{Building a BVH tree from top to bottom (root to leaves). Wrapping AABBs and splitting them into two halves recursively until reaching leaves.}
        \label{fig:three graphs}
\end{figure}

\noindent
\\
Since the Top-down approach is chosen, we will start creating the nodes from the top to the bottom. Firstly, we start creating the root node. Each node needs to save the AABB bounds ($minimum\_edge$, $maximum\_edge$), the splitting point, and the splitting axis. If the node is a leaf node we will save the assigned primitives ids.  We can calculate the $minimum\_edge$ (the minimum 3D point in our root AABB) and the $maximum\_edge$ point (the maximum 3D point in the AABB box) by easily iterating through all primitives in the scene and assigning the minimum primitive centroid to the  $minimum\_edge$ and the maximum primitive centroid to the $maximum\_edge$. The final result is $maximum\_edge = (6.6, 5.5)$ and  $minimum\_edge = (0.8,0.8)$.

\noindent
\\
After creating the root AABB, the second step is to find the splitting point by using the AABB boundaries. As we mentioned, we will find the longest axis first. To find the longest axis, we have to calculate the diagonal $d$ by subtracting the $minimum\_edge$ from $maximum\_edge $ and finding the maximum of both axes $max(maximum\_edge - minimum\_edge)$. This will give us $max((6.6-0.8) , (5.5-0.8)) = max(5.8,4.7) = 5.8$, which corresponds to the x-axis. 

\noindent
\\
Now we calculate the splitting point by just halfing the distance between $maximum\_edge $ and the $minimum\_edge$, $split\_point = \frac{0.8+6.6}{2} = 3.6$.

\noindent
\\
Then we pass all primitives that have a centroid $ < 3.6$ to the left child node and we pass the rest to the right child node.  

\noindent
\\
Recustivly we keep doing this until the number of primitives in the node is less than the maximum allowed number of primitives parameter, which in this implementation we decided to set to $1$. Then we create a leaf node that holds this primitive id. 


\begin{figure}[h]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=9cm]{images/example_bvh/tree.png}
     \caption{The generated BVH tree by using centroid splitting criteria and AABB as BV.}
     \label{fig:dice}
\end{figure}

\subsubsection{Traversal}
 The traversal phase of BVH is quite intuitive if you are familiar with how binary tree traversal works. After building the BVH tree, we start with its root node, we get its AABB boundaries and we test its intersection with the ray. If the ray intersects with the AABB, we go to its left and right children and do the same process; otherwise, we terminate. Recursively keep doing this until we reach a leaf node; the leaf node is the node that has no node children, and it is the only node that contains a primitive inside it. Then we go through the list of primitives and test each one if it intersected with the ray or not. Remember that since we are using one primitive for each leaf node the primitive's list will only contain one primitive and this will not create a linear performance burden. 

\noindent
\\
As discussed, the leaf node can include a list of primitives and not only one by setting a parameter called $max\_leaf\_premitives$ to 1; this depends on how you configure the BVH building tree method. In this report, I set the list to make it only contain one primitive. It is worth noticing that the bigger $max\_leaf\_premitives$ is, the smaller the depth of the tree becomes because we do not have to keep splitting until we reach a leaf that only contains primitives less or equal to $max\_leaf\_premitives$. Therefore, less traversal time and less memory consumption because of the number of nodes saved, on the other hand, this will lead to a long list of primitives inside the leaf node, adding a linear time complexity for iterating through all the lists which kills the purpose of using the hierarchy of the BVH to make the complexity logarithmic.

\noindent
\\
The intersection test is split into two main steps. First, we go through all the nodes in the tree, and if we hit a leaf node, we add all its primitives into a list called $hitList$. The $hitList$ list is acting as a candidate list of the primitives that might intersect with the ray.  Afterward, we go through these candidates and find which are intersected and which one is the nearest to the camera by comparing the intersecting point distance to the camera center position.

\begin{algorithm}[H]
	\caption{$intersectBVH$}\label{alg:alg1}
	\begin{algorithmic}
		\Require $ray$, $node$, $hitList$
		\If{$node$ $\rightarrow$ $boxIntersect(ray) = false $}
			\State $return\;\;false$
		\EndIf
		\If{$node$ $\rightarrow$ $isleaf$}
		    \State $hitList$ $\rightarrow$ $push(node \rightarrow premitives)$
		\Else
			\State $intersectBVH(ray, node \rightarrow leftChild,\, hitList)$
			\State $intersectBVH(ray, node \rightarrow rightChild,\, hitList)$
		\EndIf
	\end{algorithmic}
\end{algorithm}

\clearpage

\section{Linear Bounding Volume Hierarchies (LBVH)}
\subsection{Concept}
While BVH boosts the renderer's performance and makes it possible to render millions of primitives in minutes, it introduces an extra step in the rendering pipeline, which is a preprocess for building the tree. The building tree process can take half of the rendering time; nevertheless, creating this tree will make the render faster to find the intersected primitive. The question now is, can we do something about it? 

\noindent
\\
One way to solve this is to parallelize this process. This can be done if the subtrees are independent of each other. This is what Linear Bounding Volume Hierarchies do. It creates a subprocess to make them build sub trees and join them at the end of the building of the subtrees to make one node. Naturally, parallelization will boost the performance of the construction time, hence we will not compare it with the normal BVH. However, we will treat the LBVH as different splitting criteria and compare its performance with the BVH.

\noindent
\\
The first step is to transform the building tree problem into a sorting problem. We map the 3D centroid points for each primitive to one value that can be sorted. Morton codes do this mapping. Morton code map multidimensional data to one dimension while preserving the locality of the data points \protect\cite{wikipedia2022}. The transformation is done by interleaving the bits of the primitive's centroid in base 2. for example taking a 3D point (x,y,z) the result Morton code will be calculated as follows: 
 
\begin{equation}
 ...z_3y_3x_3z_2y_2x_2z_1y_1x_1z_0y_0x_0
\end{equation}

\begin{align*}
& p_x = \textcolor{brown}{1010}, \;p_y = \textcolor{red}{0111}, \;p_z = \textcolor{blue}{1100} \\
&Morton\;code = \textcolor{blue}{1}\textcolor{red}{0}\textcolor{brown}{1} \;\textcolor{blue}{1}\textcolor{red}{1}\textcolor{brown}{0} \;\textcolor{blue}{0}\textcolor{red}{1}\textcolor{brown}{1} \;\textcolor{blue}{0}\textcolor{red}{1}\textcolor{brown}{0}
\end{align*}

\noindent
\\
After mapping the 3D point to 1D Morton code, we can use a sorting algorithm as a Radix sort \protect\cite{Karras2012}.

\subsubsection{Morton Code as a Splitting Criteria}
After mapping all primitives centroid to a Morton code and sorting them, the next step is to know how to use the sorted list for building the tree. To better understand how the LBVH constructs the binary tree, we will illustrate this with a scene as shown in Figure ~\ref{fig:mortonexample}
. The scene is made out of 16 primitives distributed as shown. The first step is to generate the Morton code for each centroid point. Looking closely into the generated Morton codes of each primitive, we can note that each bit acts as a splitting plane that splits the primitives into more than one region. 

\noindent
\\
The first bit will split the y-axis into two regions. The first region with the first bit equals $1$, and the second region with the first bit equals $0$. For the binary tree, we can assign primitives with the zeros $0$xxx on the left child and the primitives with ones $1$xxx on the right. The second bit will split the scene into two areas by an x-axis plane. The third bit will split the y-axis into four regions.


\begin{figure}[H]	
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \captionsetup{justification=centering}
         \includegraphics[width=5cm]{images/example_lbvh/morton_g.png}
         \caption{}
         \label{fig:pi_4000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \captionsetup{justification=centering}
         \includegraphics[width=5cm]{images/example_lbvh/01_g.png}
         \caption{}
         \label{fig:pi_5000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \captionsetup{justification=centering}
         \includegraphics[width=5cm]{images/example_lbvh/02_g.png}
         \caption{}
         \label{fig:pi_18000}
     \end{subfigure}
        \captionsetup{justification=centering,margin=2cm}
             \hfill
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \captionsetup{justification=centering}
         \includegraphics[width=5cm]{images/example_lbvh/03_g.png}
         \caption{}
         \label{fig:pi_18000}
     \end{subfigure}
        \captionsetup{justification=centering,margin=2cm}

        \caption{(a) The generated Morton code for 2D primitive's centroids. (b) The first splitting plane splits on the y-axis. (c) Second-highest bit of the Morton code splits the x-axis in the middle. (d) The third bit splits the primitives into four regions. }
        \label{fig:mortonexample}
\end{figure}



\begin{figure}[h]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=12cm]{images/example_lbvh/tree.png}
     \caption{Generated tree by LBVH.}
     \label{fig:dice}
\end{figure}


\subsection{Implemntation}
The implementation includes two essential stages, Constructing the tree and tree Traversal. Traversal will not be repeated since the produced tree is a binary tree similar to the BVH. Hence the same traversal algorithm used in the BVH will be utilized for LBVH. But the main focus of the LBVH is building the tree.


\subsubsection{Construction}
The first step is to generate the Morton code for each primitive and to save time one can generate the Morton code for each primitive and start sorting them while reading the primitives from the scene. It is better than reading the whole scene than going through all primitive in linear time and then sorting them by Radix sort. 

\noindent
\\
Next, we start creating the nodes and split them based on the leading bits. We start with the sorted Morton code and we start searching for the first leading bit change. Once the bit flips we assign the zeros to the left child node and the rest to the right child node. We calculate the global bounding box for the current primitives and create the current node since we have all we need, an AABB box and a splitting point. We recursively keep doing this until we reach leaves and we assign the primitives indexes or ids to the leaves. Again for the LBVH, I made the depth unlimited. Also, the maximum number of primitives in a leaf was set to one.

\noindent
\\
Until this point, LBVH acts as a splitting criterion of a BVH. As we discussed, LBVH makes it trivial to parallelize the construction stage. To achieve this, we will use a simple conditional multithreading mechanism. Building the tree will only create a new thread if the number of primitives in the subtree is more than 100 primitives. Note that this is a random number chosen, but we do not want to create a new thread for small subtrees because it is not worth it anyway. Note that for a fair comparison between the data structures we will not parallelize LBVH and we will only run it on one thread. 

\begin{algorithm}[H]
\caption{$constructLBVH$}\label{alg:alg1}
\begin{algorithmic}
		\Require $allPrimitives$, $sortedMortonCodes$, $startI$, $endI$
\State $node$ $\gets$ $createNewNode()$
\State $increaseTotalNumberOfNodes()$

\State $aabb$ $\gets$ $getGlobalAABB(primitives)$
\State $primitives$ $\gets$  $endI$ - $startI$
\If{$primitives = 0$}
	\State $node \rightarrow isleaf \gets true$
	\State $node \rightarrow prims \gets allPrimitives[startI]$
	\State \Return $node$
\EndIf

\State $split \gets findSplitPoint(sortedMortonCodes, startIndex, endIndex)$
\State $node \rightarrow leftchild  \gets constructLBVH(allPrimitives, startI, split)$
\State $node \rightarrow rightchild  \gets constructLBVH(allPrimitives, split, endI)$
\State \Return $node$
\end{algorithmic}
\end{algorithm}
\clearpage



\section{K dimensional tree (Kd-Tree)}
\subsection{Concept}
We have already covered two data structures accelerators, the BVH and LBVH. Both methods are under the category of object subdivision. This chapter will discuss and implement a different accelerator called KD-Tree which is a spatial subdivision type. Kd-Tree is a traditional data structure that organizes K-dimensional points into a binary tree for easy retrieval. The Kd-Tree can have several dimensions at each level, unlike a typical binary tree. It has been frequently utilized in multidimensional crucial data search because of its effective performance in resolving multidimensional searching issues.

\noindent
\\
Unlike the previous techniques, Kd-Tree is a method categorized as a spatial (space) subdivision. Spatial subdivision algorithms split the space into areas and assign the primitives that fall in those areas.

\noindent
\\
The main idea is to divide the scene into regions. Each region will have a list of primitives that intersect it. When we start rendering and start the intersection tests, we start looking for areas that intersect with the ray, and if we find an intersection, we only test the primitives that fall in it.
The following Figure ~\ref{fig:kdtreedemo} gives an overview of how the spaces are divided: 

\begin{figure}[h]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=10cm]{images/kdtree/example_demo.png}
     \caption{The Kd-Tree is built by splitting the scene into four regions where for each split one axis is chosen with a splitting point.  The first split is done on the x-axis then the y-axis and the last split is on the x-axis again. \protect\cite{Pharr2016}}
        \label{fig:kdtreedemo}
\end{figure}



\subsubsection{Compact tree representation}
Unlike what we did in the BVH, the representation of the Kd-Tree will be compact. This means rather than saving two children pointers left and right, we will save all nodes in an array, where the left child lives right after the parent node in the array, and the right child can be reached by saving the offset. Doing so improves cache, memory, and thus overall system performance.


\begin{figure}[h]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=8cm]{images/kdtree/compact.png}
     \caption{The linear layout of a Kd-Tree in Memory representation. The first child is discovered immediately after the parent node in memory. An offset pointer, illustrated here with lines and arrows, is used to locate the second child. The tree's leaf nodes (D, E, and C) have no children. \protect\cite{Pharr2016}}
        \label{fig:dice}
\end{figure}


\subsubsection{The Surface Area Heuristic (SAH)}
Building a binary tree from top to bottom can be done by using greedy \textbf{Surface Area Heuristics (SAH)}. The original scene is recursively partitioned using a greedy strategy for minimizing expected traversal cost. As the name suggested this method of splitting nodes considers the area/volume of the primitives to find the splitting point.

\noindent
\\
Given a collection of $N$ primitives in a node tree with total 3D volume $V$, and assuming that the split point chosen will partition the space into two halves $L$ and $R$ with a number of triangles $N_L$ and $N_R$, and corresponding volumes $V_L$ and $V_R$, respectively. With the previous configuration, the projected traversal cost can be approximated as

\begin{equation}
Cost(V) = C_T + C_I(\frac{SA(V_L)}{SA(V)}N_L \frac{SA(V_R)}{SA(V)}N_R)
\end{equation}

\noindent
\\
Where: $V$: Total volume, $C_T$: Cost of traversal, $C_I$: Cost of intersection, $SA$: Surface area, $N$: Number of premitives, $•L$: Left, $R$: Right.

\noindent
\\
The following example visualizes and illustrates how the SAH works. Given a scene consisting of 7 primitives, we would like to find the best split by using the SAH method. Because the intersection cost depends on the ray tracer implementation we will set it to 1. In contrast, the estimated traversal cost was set to $\frac{1}{8}$. We will set the number of buckets to 8. The previous numbers are chosen for easier calculation only.

\noindent
\\
Starting with the first iteration, the green colour represents the left space $L$, and the red colour represents the right space $R$. Since the example is in 2D, the $SA $ equals the width multiplied by the height of the rectangle. Each pixel has an area of 1. The SA of each rectangle is illustrated in Figure ~\ref{fig:sahdemo}. The overall surface area $SA(V)$ equals the summation of all the 7 primitives $1+1+4+4+4+1+1 = 16$. We can now substitute all the given information into the equation we get: 


\begin{align*}
& Cost\_iteration\_1 =  \frac{1}{8} + (\frac{1}{16}(1) +\frac{1+4+4+4+1+1}{16}(6)) = 5.81 \\
&Cost\_iteration\_2 =  \frac{1}{8} + (\frac{1+1}{16}(2) +\frac{4+4+4+1+1}{16}(5)) = 4.75 \\
&Cost\_iteration\_4 =  \frac{1}{8} + (\frac{1+1+4}{16}(3) +\frac{4+4+1+1}{16}(4)) = 3.75 \\
&Cost\_iteration\_7 =  \frac{1}{8} + (\frac{1+1+4+4+4+1}{16}(6) +\frac{1}{16}(1)) = 5.81 \\
\end{align*}


\noindent
\\
We choose the minimum cost. In the previous iterations, it is the 4th and then assigns the primitives on the left to the left node and the right primitives to the right node. Note that for simplicity I sis not use primitives that intersect with each other. Unlike BVH, some primitives can be set to both left and right if they are between the bucket's splitting point.


\begin{figure}[H]	
     \centering
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \includegraphics[width=5cm]{images/kdtree/grid_2.png}
         \caption{$1^{st} $ iteration.}
         \label{fig:pi_4000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \includegraphics[width=5cm]{images/kdtree/grid_3.png}
         \caption{$2^{nd} $ iteration.}
         \label{fig:pi_5000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \includegraphics[width=5cm]{images/kdtree/grid_5.png}
         \caption{$4^{th} $ iteration.}
         \label{fig:pi_18000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.475\textwidth}
         \centering
         \includegraphics[width=5cm]{images/kdtree/grid_8.png}
         \caption{$7^{th} $ iteration.}
         \label{fig:pi_18000}
     \end{subfigure}
        \captionsetup{justification=centering,margin=2cm}
        \caption{Finding the best splitting point by using SAH. The left region is represented by green and the right region is represented by red.}
        \label{fig:sahdemo}
\end{figure}



\subsection{Implemntation}

Kd-Tree is a variant of Binary space partitioning (BSP) tree. BSP trees use planes to divide the space into regions. It follows a top-down approach where a bounding box bounds the whole scene. If the number of primitives inside the bounding box exceeds a pre-defined parameter, we will name it maxPrims then, the box is split into two sub-regions based on chosen splitting criteria. Each primitive is associated with the corresponding box/region that it intersects with. This means duplicated primitives that can live in more than one box, unlike the BVH.

\noindent
\\
The procedure keeps repeating recursively until one of the two ending conditions occurs. Either the number of primitives in the sub-regions is less than maxPrims or the other parameter, maxdepth is reached. maxdepth parameter is used to control the depth of the tree. 

\noindent
\\
In order to increase the efficiency of traversal and tree construction, kd-trees simply limit the splitting plane to only be perpendicular to one of the coordinate axes. However, this compromises some flexibility in how space is divided.

\subsubsection{Construction}

The recursive top-down algorithm is used to construct the kd-tree. We have a collection of primitives that overlap the axis-aligned space region at each step. Either the region is divided into two smaller ones and transformed into an inner node, or the recursion is stopped by making a leaf node out of the overlapping primitives.

\noindent
\\
In the Kd-tree, we will save the nodes in an array and not in a tree representation, as mentioned before, increasing caching. The issue is how to predetermine the number of nodes before building the tree to initiate the array? There are two approaches here. The first is to build the binary tree and then flatten it to an array (compact representation). The second approach is to allocate memory as we build the tree dynamically. The first approach needs two steps to build the tree and then transform it into a compact form, adding an extra step that reduces performance. Also, it consumes more memory as it eeds to save the tree and adds an array that contains the same number of nodes as the tree. The second approach is preferred as it consumes less memory and improves performance. However, it needs better handling for the memory allocation, this complexity depends on the implmentation and the programming language is used, so I will not explain the implementation. 

\noindent
\\
For building the tree, the maximum allowed depth is needed to be given. However, what depth is preferred, large or too small? Large depth will increase the number of nodes, increasing memory consumption. Reducing it will reduce the number of nodes but will make the traversal time more linear, killing the use of the binary tree to reduce the complexity. Based on  PBRT book, a generic formula can be used to calculate the depth. This formula works for a various scenes, $N$ is the number of primitives in the scene. 


\begin{equation}
depth = 8 + 1.3log(N)
\end{equation}

\noindent
\\
Since we are using memory allocation dynamically for the nodes array, each time the array is full, we will then reallocate more memory duoble the size of the old array.

\noindent
\\
The splitting point will be found using the SAH algorithm, unlike in the BVH where we used the median point. The advantage of using median point is intuitive to calculate and implement; nevertheless, it does not care about the area/volume of the primitive, unlike SAH, which considers the area/volume. Two parameters $t_{isect}$ and $t_{t_trav}$ are used in the SAH that will be tested and tweaked to find the best parameters. There are different methods to search for the best parameters for the best scenes; nevertheless, we will focus on the ratio between the two parameters instead. PBRT suggests to used 80 and 1, respectively, and other references suggest that the values should stay closer to each other. 

\noindent
\\
One extra parameter, "emptyBonus" denoted as $b_e$ will be added to the SAH algorithm. Since rays traveling through empty areas can progress to the next kd-tree node without having to do any ray-primitive intersection checks, hence there is a little advantage for picking splits when one of the children has no primitives overlapping it. The parameter takes a value between 0 and 1 if one of the regions is empty and 0 otherwise. 

\begin{equation}
Cost(V) = C_T + (1-b_e)C_I(\frac{SA(V_L)}{SA(V)}N_L \frac{SA(V_R)}{SA(V)}N_R)
\end{equation}

\noindent
\\
One challenge left, if we want to consider all the splitting points as candidates, computing the cost of splitting is expensive, but as we mentioned before, we can use a fixed number of buckets. However, which is the best number for this parameter? The bigger the number, the more accurate the splitting point will be at the cost of building the tree's performance because more calculations are needed. Instead of considering splits at intermediate points, the minimal cost will be reached at a split that coincides with one of the faces of one of the bounding boxes of the primitive. Hence we will need at each cost calculation at most $2 * N$ where $N$ is the number of primitives.

\begin{figure}[H]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=10cm]{images/kdtree/projected_bboxes.png}
     \caption{Only six splitting points are considered. Taking $a_1$ as the splitting point will leave a bounding box under it, B overlapping it, and C above it. \protect\cite{Pharr2016}}
        \label{fig:dice}
\end{figure}

\noindent
\\
Some edge cases can occur when the same number of primitives are assigned for both children. At this point, we are not gaining any performance from creating an interior node. The solution is to try other axes instead of the best-chosen axis. If the same edge case occurred for all axes, we would create one leaf node and assign all the primitives. It also can be worse to split than creating a leaf node based on the SAH algorithm. In that case, a leaf node is created rather than splitting. 

\noindent
\\
The KD-Tree has a variety of implementations, the one used in this project is based on (Physically Based Rendering). The implementation generates a binary tree that focuses on less memory consumption and finds the best split by using the SAH method for splitting. We will be using a top-down approach as we did in BVH. We will split the implementation into two phases: Tree construction and tree traversal.


\subsubsection{Traversal}
The kd tree traversal is different from the BVH traversal we mentioned. BVH was a binary tree traversal where we start with the root node and go to the left or right child. On the other hand, the Kd-tree uses the compact form array. 


\begin{figure}[H]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=10cm]{images/kdtree/traversal.png}
     \caption{(a) The ray is intersected with the bounds of the tree, giving an initial parametric $[t_{min}, t_{max}]$ range to consider. (b) Because this range is nonempty, it is necessary to consider the two children of the root node here. The ray first enters the child on the right, labeled “near,” where it has a parametric range $[t_{min}, t_{split}]$. If the near node is a leaf with primitives in it, ray–primitive intersection tests are performed; otherwise, its children nodes are processed. (c) If no hit is found in the node, or if a hit is found beyond $[t_{min}, t_{split}]$, then the far node, on the left, is processed. (d) This sequence continues—processing tree nodes in a depth-first, front-to-back traversal—until the closest intersection is found or the ray exits the tree. \protect\cite{Pharr2016}}
        \label{fig:dice}
\end{figure}

\noindent
\\
The first intersection test will start by testing if the ray intersects the global bounding box of the whole kd-tree $[t_{min}, t_{max}]$. If it returns false, we stop testing other nodes in the tree instantly because this means the ray does not pass any primitive.

\noindent
\\
If it returns true, we proceed to the next step, if the current node is a leaf or an interior node. If it is a leaf node, we iterate through the list of the primitives assigned to the node. As we discussed, we are not saving the primitives directly in the leaf node. We only save the number of primitives and the offset of the indices. This is a huge performance advantage, especially for the kd-tree, because in the kd-tree, one primitive can be in more than one node at a time. In terms of memory usage, if one leaf contains an N number of primitives, then there is a high chance of duplication of information with another leaf that contains these N primitives. You can imagine with a million primitives. This can be at least twice the number of the original primitives. Since we are using a depth-first search, if we reach the leaf node, we will decrement the node index to go back one step, then we reassign the current node and its tMin and tMax values. Note that before going through all the primitives, if the ray already intersected primitives in other nodes and those other nodes and the intersected point is less than the $t_{min}$ of the current node, then we are sure that we can not do better. We will not find any closer primitive in the leaf node. Hence we break and return. 

\noindent
\\
Otherwise, if it is an interior node, we would like to test its children, and unlike we did in the BVH we were going left and then right. This time we will use the intersection point to determine which is the left and the right node. By comparing the splitting point with the intersected point, we can determine which of the children has a higher chance of being intersected first. This can be done quickly by checking if $t_{split} > t_{max}$, then we do not need to check the far child node, same we check if $t_{split} < t_{min}$, then we do not check the far child node. Otherwise, we check them both by starting with the near and proceeding to the far. 

\begin{figure}[H]	
     \centering
     \captionsetup{justification=centering,margin=2cm}
     \includegraphics[width=10cm]{images/kdtree/traversal_case.png}
     \caption{Different scenarios prove the ray should not intersect both children.(a) The ray intersects the splitting plane at a point bigger than the $t_{max}$; hence we are sure it will not intersect the far child node. A negative sign denotes the bottom ray's direction away from the dividing plane. (b) In this case, the ray intersects the box at a point after the splitting plane, indicating that the  near child is avoided. \protect\cite{Pharr2016}}
        \label{fig:dice}
\end{figure}

\clearpage

\section{Performance Analysis}
In this chapter, we will analyze the different data structures used (BVH, LBVH, Kd-Tree) and how they perform against different scenes. We will pick up one data structure and tweak its different parameters and analyze how small changes in the parameter can affect the performance.

\noindent
\\
The following settings are used in the raytracer:

\newcommand\T{\rule{0pt}{2.6ex}}       % Top strut
\newcommand\B{\rule[-1.2ex]{0pt}{0pt}} % Bottom strut

\begin{table}[H] 
\centering 
{\footnotesize
\begin{tabular}{ P{2.5cm} P{5cm}  P{5cm}}      % centered columns (3 columns) 
\hline \hline
Property & Value \T\B  \\
\hline \hline
Machine & Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz, RAM 16GB \T\B \\
 \hline
Resolution & 640x480  \T\B
\\
 \hline
Programming language & C++  \T\B 
\\ 
 \hline
Shader & Phong illumination \T\B 
\\
 \hline
\#Cameras & 1 \T\B 
\\
\#Lights & 1  \T\B 
\\ 
 \hline
 Models extention& .obj \T\B 
\\ 
 \hline
Anti-aliasing samples & 1 \T\B 
\\ 
\hline \hline
    \end{tabular}
}
  \caption{The settings used for the Raytracer}
\end{table}

\subsection{How tweaking the data structure parameters affect performance}
Before jumping to the next chapter "Tests and Performance Analysis", I would like to emphasize and explain how a small change in the parameter of building the tree can affect the performance significantly. 

\noindent
\\
Figure 20 shows two different constructed binary trees based on the same algorithm Kd-Tree and the same input scene, however by changing the maximum number of premitives in leaf node parameter, we can note that one tree is shorter than the other! How would this affect the performance? 

\noindent
\\
A deeper tree means more nodes which leads to more memory consumption. Moreover, if the splitting criteria are too bad this can lead to a long traversal time. On the other hand, a shallow tree can lead to fewer nodes but leaves that contain more primitives that will require a linear search (Brute force).    


\begin{figure}[H]	
     \centering
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         \captionsetup{justification=centering}
         \includegraphics[width=\textwidth]{images/kdtree/visaul_scene_1_new.png}
         \caption{Kd-Tree generates regions (AABB) in a simple scene.}
         \label{fig:pi_4000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.6\textwidth}
         \centering
         \captionsetup{justification=centering}
         \includegraphics[width=\textwidth]{images/kdtree/visaul_tree_11_new.png}
         \caption{The resulting binary tree is based on the Kd-Tree algorithm with setting the maximum number of primitives in the leaf node parameter to 1.}
         \label{fig:pi_5000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.3\textwidth}
         \centering
         \captionsetup{justification=centering}
         \includegraphics[width=\textwidth]{images/kdtree/visaul_scene_2_new.png}
         \caption{Kd-Tree generates regions (AABB) in a simple scene.}
         \label{fig:pi_5000}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.6\textwidth}
         \centering
         \captionsetup{justification=centering}
         \includegraphics[width=\textwidth]{images/kdtree/visual_tree_2_new.png}
         \caption{The resulting binary tree is based on the Kd-Tree algorithm with setting the maximum number of primitives in the leaf node parameter to 2.
}
         \label{fig:pi_5000}
     \end{subfigure}
        \captionsetup{justification=centering,margin=2cm}
        \caption{Two different constructed kd-trees with the same implementation and scene but with different parameter.}
        \label{fig:three graphs}
\end{figure}

\noindent
\\
In order to demonstrate this in simple math. Assuming the time consumed to test the intersection with an AABB box will take $0.1ms$. We take the path demonstrated in the Figure in green that is been generated to find the intersection with the yellow sphere. (b) needs five AABB tests this will result in $0.5ms$ to find the intersection, unlike in (d) where only three AABB tests are needed resulting in $0.3ms$ to find the sphere. Obviously, the deeper tree has less performance! Nonetheless, we did not put the intersection cost of the spheres into consideration! In this example the sphere intersection cost is tiny but what if we replace the spheres with more complex models will the shallow tree still be better to use? In a shallow tree, the yellow sphere can be after the blue sphere in the list, hence one has to test the blue sphere first and then jump to the yellow. If the blue sphere (Model) in general has a high intersection cost let's say $0.3ms$. then this will be added to the shallow tree cost (d) to become $0.3ms + 0.3ms = 0.6ms$ which is larger than the long path in the deep tree (b). Even though the model is as simple as a triangle or sphere only, we need to remember that for the long list that contains a big number of primitives this will add a leaner complexity.

\noindent
\\
To investigate the concept of how changing the data structure parameters impacts the resulting tree which leads to different performance metrics, I have chosen one data structure Kd-Tree to verify this. In this experience, we will try changing two main parameters: The maximum number of primitives assigned to each leaf (maxPrims) and the Maximum depth of the tree (depth). For better testing, I have fixed the model which is the Stanford bunny. Moreover, other SAH parameters are fixed to focus only on the two parameters mentioned. 

\noindent
\\
By changing the maxPrims parameter and fixing the others we can note that the larger the value the less it takes to build the tree, for example when increasing maxPrims from  1 to 100, the build time increased by almost 2X. This is predictable as we discussed before, when the maxPrims parameter is big we stop the recursion of building the tree hence we stop creating more interior nodes as shown in the table the total number of nodes decreases by almost 418X consequently the tree depth becomes smaller. On the other hand, we note that rendering time increased by 1.2X. This is because for some leaf nodes now we have nodes with 100 primitives that the ray has to go through them linearly and test them until it finds the right primitive or even worse not find an intersection after going through 100 primitive intersections. This explains why the number of intersection tests shown in the table has increased by almost  61X. When the value is chosen between 10, this gave the best of both worlds, as the building and the rendering time are acceptable. 





\begin{table}[ht] 
\centering 
{\footnotesize
\begin{tabular}{ P{2.5cm} ||P{2.3cm}  P{2.3cm}  P{2.3cm} P{2.3cm}  P{2.3cm}}      % centered columns (3 columns) 
\hline\hline                                      %inserts double horizontal lines
\Includegraphics[height=1in]{images/stanford-bunny-black.png}
& \#Primitives  & \#Nodes & \#Primitives intersection tests & Build(s) & Rendering(s) \\ [0.5ex] % inserts table heading 
\hline
    \end{tabular}
}
\end{table}
\vspace{-2em}
\begin{table}[ht] 
\centering 
{\footnotesize
\begin{tabular}{ P{2.5cm} ||P{2.3cm}  P{2.3cm}  P{2.3cm} P{2.3cm}  P{2.3cm} }      % centered columns (3 columns) 
 \hline
\\
maxPrims = 1& 35, 947 & 418, 548 & 192, 171 &  5.214 s & 20.845 s\\
\\
maxPrims = 10& 35, 947 & 19, 229 & 1, 381, 296 & 2.033 s & 20.211 s\\
\\
maxPrims = 100& 35, 947 & 1, 461 & 11, 761, 329 & 2.865 s & 24.062 s\\
\\
\hline \hline
\\
depth = 5 & 35, 947 & 61 & 140, 964, 745 &  0.7 s & 37.762 s \\
\\
depth = 10& 35, 947 & 1, 435 & 10, 571, 611 & 1.239 s & 11.566 s\\
\\
depth = 28& 35, 947 & 44, 852 & 683, 669 & 1.757 s & 9.606 s\\
\\
depth = 100& 35, 947 & 44, 854 & 683, 669 & 1.871 s & 9.546 s\\
\\
\hline \hline
    \end{tabular}
}
  \captionsetup{justification=centering,margin=2cm}
  \caption{Changing Kd-Tree parameters and how they affect performance by using \protect\cite{stanfordbunny}}
\end{table}

\noindent
\\
The depth parameter has a different effect on the number of nodes where when the value changed from 5 to 10 the number of nodes increased by almost 24X which reduced the rendering time by almost 3X.  Even small values of the depth reduce the building time the rendering time which is usually the most critical stage in the raytracing pipeline is increased tremendously. Using the formula mentioned to set the depth dynamically depending on the scene, we end up with a value equal to 28 in this scene (Stanford bunny), this value increases the rendering time even more by almost 4X in comparison to depth equals to 5. Nevertheless increasing the depth more to 100 resulted in no performance gain as we reached a saturation point. Although I took the formula from the book PBRT for granted it seems that it delivers a decent result in this scene. 

\noindent
\\
What about tweaking both parameters to find the best result? In order to find the best combination of parameters for a random scene one can use one of the well known parameter optimization techniques such as  Grid Search, we will not cover this part in this report as I have used a simple manual method. 

\subsection{Investigating different data structures}
I have used different models with a diverse range of primitives for proper comparison. The models Stanford-bunny, Igea, Asian Dragon, and Happy Buddha used are taken from the following repository [commontest].

\noindent
\\
For all the three used data structures I have calculated a collection of useful mercies.  Since each data structure needs a pre-processing time to be constructed and built, build time in seconds corresponds to how many seconds each data structure took to be ready to be used for the rendering stage. Rendering time render is also important to be measured, as it indicates how long the overall rays took to travel through the scene. The number of intersection tests done for the primitives is also important as it explains how many intersection tests are done in the rendering phase, usually less number of intersection tests indicates better performance. The total number of nodes metric indicates the complexity of the constructed tree and how deep is it. 

\noindent
\\
The first metric to investigate is the building time. We can note that BVH is the fastest to build the tree and Kd-Tree takes 3X for the Stanford bunny and 6X for the Happy buddha, nonetheless, LBVH stays in between! BVH is the fastest because it uses simple splitting criteria which is the median of the AABB box, this is a cheap performance execution, moreover, it uses a simple tree representation and does not use a compact form. LBVH is almost 2X of the BVH, even though both are using the same binary tree the splitting criteria are different. LBVH has to map the center point of the 3D primitive to a Morton code, sort it by radix sort and then find a splitting point. These extra three stages add extra complexity to the building phase, hence LBVH takes more time than BVH for this implementation. Kd-Tree consumes so much time in the building phase since it uses the SAH algorithm for splitting nodes. As we explained already with an example the SAH method can be expensive to compute, especially for some edge cases where the splitting point can not be found and the algorithm tries the whole three different axes until it either find the best split or just split the AABB into halves. 

\noindent
\\
The second metric is the rendering time.  The first note is that both BVH and LBVH have similar performance at rendering, the reason is that both are using the same rendering algorithm. By adding both building and rendering time we can note that BVH spends less time than LBVH. So why are we using LBVH? LBVH is mostly beneficial on the construction time as the tree can be built on multi threads, however, I did not include this as it is intuitive multithreading will increase any algorithm performance. Kd-Tree on the other hand spends less time on the smaller models with few primitives as well as the ones with 1 million primitives. Adding both buildings the rendering time we note that Kd-Tree consumes much more time than the other data structures. 

\noindent
\\
Looking at the number of nodes and the number of intersections with primitives we can see that kd-Tree is a clear winner, and this explains why Kd-Tree spends less time on rendering than BVH and LBVH. Note that number of nodes in the Kd-Tree is less due to two reasons. The first reason is that we are using the equation mentioned to calculate the maximum depth for the tree which will restrict its recursions and the nuumber of splitting, unlike BVH and LBVH where both do not care about depth in my implementation.  The second reason is that we used SAH for splitting which looks for the tradeoff between the cost of splitting or just creating a leaf node and stopping. 

\noindent
\\
\begin{table}[H] 
\centering 
{\footnotesize
\begin{tabular}{ P{2.5cm}||P{2.5cm}P{2.5cm} P{2.5cm} P{2.5cm}  }      % centered columns (3 columns) 
\hline\hline                                      %inserts double horizontal lines
& Bunny  & Igea & Asian Dragon & Happy Buddha \\ [0.5ex] % inserts table heading 
\hline\hline 

&
\Includegraphics[height=1in]{images/stanford-bunny-black.png}& \Includegraphics[height=1in]{images/igea-black.png} & \Includegraphics[height=1in]{images/xyzrgb_dragon.png} & \Includegraphics[height=1in]{images/happy-black.png} \\

\hline \hline
\\
\#Primitives & 35, 947  & 134, 345 & 539, 205 & 1, 078, 410 \\ [0.5ex] % inserts table heading 
\\
\hline \hline

\\
BVH build(s)& 0.849 s& 2.739 s & 21.105 s & 34.687 s \\
\\
LBVH build(s)& 1.272 s& 4.401 s & 45.98 s & 58.234 s \\
\\
Kd-Tree build(s)& 2.346 s& 30.075 s & 120.078 s & 211.078 s \\
\\
\hline \hline
\\
BVH render(s)& 17.707 s& 13.986 s & 41.588 s & 51.516 s \\
\\
LBVH render(s)& 11.512 s& 13.796 s & 40.744 s & 51.14 s \\
\\
Kd-Tree render(s)& 9.405 s& 12.111 s & 45.292 s & 34.292 s \\
\\
\hline \hline
\\
BVH \#int. tests & 139, 926 & 365, 715  & 2, 429, 951  & 3, 279, 593  \\
\\
LBVH \#int. tests & 93, 641 & 365, 712  & 2, 429, 942  & 3, 279, 593  \\
\\
Kd-Tree \#int. tests & 128, 943 & 74, 516  & 483, 710  & 943, 201  \\
\\
\hline \hline
\\
BVH \#nodes & 71, 893 & 268, 689  & 1, 078, 409  & 2, 156, 819  \\
\\
LBVH \#nodes & 71, 889 & 268, 669  & 1, 077, 768  & 2, 156, 352  \\
\\
Kd-Tree \#nodes & 418, 661 & 2, 830, 597  & 415, 406  & 375, 243  \\
\\
\hline \hline

    \end{tabular}
}
\captionsetup{justification=centering,margin=2cm}
\caption{Comparison between BVH, LBVH and Kd-Tree by using \protect\cite{stanfordbunny}, \protect\cite{stanfordxyzdragon}, \protect\cite{buddha}}
\end{table}

\noindent
\\
Note that even though the average performance is correlated with the number of primitives in the scene, however, there are some scenarios where the performance is not behaving as expected. For example, looking at the Kd-Tree number of nodes can spike up, this is because not only the number of primitives important to choosing the right data structure but other perspectives related to the scene can affect the performance not only the number of primitives.  The next tests try to cover some of them.

\noindent
\\
\subsection{Investigating much more complex scenes}

\begin{table}[H] 
\centering 
{\footnotesize
\begin{tabular}{ P{2.5cm}||P{5cm}P{5cm} }      % centered columns (3 columns) 
\hline\hline                                      %inserts double horizontal lines
& Trees & Sci-Fi Tropical City   \\ [0.5ex] % inserts table heading 
\hline\hline 

&
\Includegraphics[width=5cm]{images/tree.png}
& \Includegraphics[width=5cm]{images/SCIFI.png}
\\

\hline \hline
\\
\#Primitives & 252, 178  & 90, 811\\ [0.5ex] % inserts table heading 
\\
\hline \hline

\\
BVH build(s)& 4.373 s& 1.556 s\\
\\
LBVH build(s)& 12.062 s& 5.408 s \\
\\
Kd-Tree build(s)& 55.325 s& 14.164 s \\
\\
\hline \hline
\\
BVH render(s)& 42.028 s& 54.690 s \\
\\
LBVH render(s)& 39.330 s& 49.636 s \\
\\
Kd-Tree render(s)& 22.822 s& 25.705 s  \\
\\
\hline \hline
\\
BVH \#int. tests & 907, 969 & 1, 250, 079  \\
\\
LBVH \#int. tests & 914, 992 & 1, 031, 416  \\
\\
Kd-Tree \#int. tests & 4, 486, 021 & 2, 813, 475  \\
\\
\hline \hline
\\
BVH \#nodes & 131, 047 & 65, 535 \\
\\
LBVH \#nodes & 131, 038 & 65, 530 \\
\\
Kd-Tree \#nodes & 511, 023 & 272, 881\\
\\
\hline \hline

    \end{tabular}
}
\end{table}
\subsubsection{Trees}
Special thanks to \protect\cite{trees} for the Trees 3D model. The interesting thing about this scene is that it has a high discrepancy, where some primitives are creating clusters at regions such as the leaf of the trees where there is a compact number of primitives but with some empty spaces between them, on the other hand, there is the ground the sky which is empty regions. I would like to note here that I am not supporting any textures in my Raytracer. 


\noindent
\\
Looking at the result we can note that LBVH and BVH are still delivering almost the same result, even though the building and rendering times differ, the overall performance is relatively close. The number of generated nodes is similar. Kd-Tree consumes more than double the time to construct the tree and it generates almost 4.5 million nodes which are almost 4.5X number of nodes in BVH and LBVH, however, the rendering time is almost half. This is because Kd-Tree allows the same primitives to be in more than one node leading to duplication, more nodes, and a deeper binary tree. 

\noindent
\\
We can note that when the Kd-Tree outperformed BVH and LBVH in terms of rendering time even though when it was previously tested on Igea and the Asian Dragon it did not outperform the other data structures. Even though the number of primitives is between 134k and 539K the result we would expect to be in between or at least the Kd-tree still suffering but this was not the result. This scene gives hint on how different data structures can perform differently based on the number of primitives and the distribution of primitives. 
\subsubsection{Sci-Fi Tropical City}
Special thanks to \protect\cite{scifi} for the Sci-Fi Tropical City 3D model.
This scene has more details than the Trees even though the number of primitives is less. The same result for both BVH and LBVH where BVH outperformed LBVH in the building time but LBVH outperformed BVH in rendering time, but the overall time is almost similar. Kd-Tree again outperformed both BVH and LBVH in the rendering time. Interestingly the number of nodes is less than nodes generated in the Stanford bunny which was more than the 3x number of the Sci-fi scene. 

\noindent
\\
\clearpage

\section{Conclusion}
The author thanks his supervisor \textbf{Prof.Dr.-Ing. Matthias Teschner} once again for the guidance throughout this project.
	
\clearpage

\bibliographystyle{apacite}
\bibliography{References}

\end{document}
